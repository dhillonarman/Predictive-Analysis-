{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOqGxUzdizoSxDpnU+aI5Ys",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhillonarman/Predictive-Analysis-/blob/main/102216076_Sampling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuXktcNB2KL1",
        "outputId": "d97ed17a-2bea-4ead-e43e-2d3cc63c1abf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-330a5a13c424>:38: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  sampling_methods['Stratified'] = balanced_dataset.groupby('Class').apply(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sampling Method: Random | Model: LogReg | Accuracy: 0.50\n",
            "Sampling Method: Random | Model: DecTree | Accuracy: 1.00\n",
            "Sampling Method: Random | Model: RandForest | Accuracy: 0.50\n",
            "Sampling Method: Random | Model: XGBoost | Accuracy: 0.50\n",
            "Sampling Method: Random | Model: GradBoost | Accuracy: 0.50\n",
            "Sampling Method: Stratified | Model: LogReg | Accuracy: 0.50\n",
            "Sampling Method: Stratified | Model: DecTree | Accuracy: 0.50\n",
            "Sampling Method: Stratified | Model: RandForest | Accuracy: 0.50\n",
            "Sampling Method: Stratified | Model: XGBoost | Accuracy: 0.50\n",
            "Sampling Method: Stratified | Model: GradBoost | Accuracy: 0.50\n",
            "Sampling Method: Systematic | Model: LogReg | Accuracy: 1.00\n",
            "Sampling Method: Systematic | Model: DecTree | Accuracy: 1.00\n",
            "Sampling Method: Systematic | Model: RandForest | Accuracy: 1.00\n",
            "Sampling Method: Systematic | Model: XGBoost | Accuracy: 1.00\n",
            "Sampling Method: Systematic | Model: GradBoost | Accuracy: 1.00\n",
            "Sampling Method: Cluster | Model: LogReg | Accuracy: 0.93\n",
            "Sampling Method: Cluster | Model: DecTree | Accuracy: 0.96\n",
            "Sampling Method: Cluster | Model: RandForest | Accuracy: 0.98\n",
            "Sampling Method: Cluster | Model: XGBoost | Accuracy: 0.98\n",
            "Sampling Method: Cluster | Model: GradBoost | Accuracy: 0.99\n",
            "Sampling Method: Bootstrap | Model: LogReg | Accuracy: 1.00\n",
            "Sampling Method: Bootstrap | Model: DecTree | Accuracy: 0.50\n",
            "Sampling Method: Bootstrap | Model: RandForest | Accuracy: 0.50\n",
            "Sampling Method: Bootstrap | Model: XGBoost | Accuracy: 0.50\n",
            "Sampling Method: Bootstrap | Model: GradBoost | Accuracy: 0.50\n",
            "\n",
            "Best Sampling Technique and Model:\n",
            "Sampling Method: Random\n",
            "Model: DecTree\n",
            "Accuracy: 1.00\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/AnjulaMehto/Sampling_Assignment/main/Creditcard_data.csv\"\n",
        "data = pd.read_csv(url)\n",
        "\n",
        "features = data.drop(columns=['Class'])\n",
        "target = data['Class']\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_balanced, y_balanced = smote.fit_resample(features, target)\n",
        "\n",
        "balanced_dataset = pd.concat([pd.DataFrame(X_balanced, columns=features.columns),\n",
        "                              pd.DataFrame(y_balanced, columns=['Class'])], axis=1)\n",
        "\n",
        "confidence_lvl = 0.95\n",
        "error_margin = 0.05\n",
        "p_hat = y_balanced.mean()\n",
        "z_value = 1.96\n",
        "\n",
        "random_sample_size = int((z_value*2 * p_hat * (1 - p_hat)) / (error_margin*2))\n",
        "strata_var = balanced_dataset['Class'].value_counts(normalize=True).std()\n",
        "if strata_var == 0:\n",
        "    strata_var = 1\n",
        "stratified_sample_size = int((z_value*2 * p_hat * (1 - p_hat)) / ((error_margin / strata_var)*2))\n",
        "num_clusters = 5\n",
        "cluster_sample_size = int((z_value*2 * p_hat * (1 - p_hat)) / ((error_margin / num_clusters)*2))\n",
        "\n",
        "sampling_methods = {}\n",
        "\n",
        "sampling_methods['Random'] = balanced_dataset.sample(n=random_sample_size, random_state=42)\n",
        "\n",
        "sampling_methods['Stratified'] = balanced_dataset.groupby('Class').apply(\n",
        "    lambda x: x.sample(int(stratified_sample_size * len(x) / len(balanced_dataset)), replace=True, random_state=42)\n",
        ").reset_index(drop=True)\n",
        "\n",
        "k = len(balanced_dataset) // random_sample_size\n",
        "sampling_methods['Systematic'] = balanced_dataset.iloc[::k, :].reset_index(drop=True)\n",
        "\n",
        "balanced_dataset['Cluster'] = pd.cut(balanced_dataset['Time'], bins=num_clusters, labels=False)\n",
        "chosen_clusters = balanced_dataset['Cluster'].sample(num_clusters // 2, random_state=42).unique()\n",
        "sampling_methods['Cluster'] = balanced_dataset[balanced_dataset['Cluster'].isin(chosen_clusters)].reset_index(drop=True)\n",
        "\n",
        "sampling_methods['Bootstrap'] = balanced_dataset.sample(n=random_sample_size, replace=True, random_state=42)\n",
        "\n",
        "ml_models = {\n",
        "    'LogReg': LogisticRegression(max_iter=1000),\n",
        "    'DecTree': DecisionTreeClassifier(random_state=42),\n",
        "    'RandForest': RandomForestClassifier(random_state=42),\n",
        "    'XGBoost': XGBClassifier(eval_metric='logloss', random_state=42),  # Removed use_label_encoder argument\n",
        "    'GradBoost': GradientBoostingClassifier(random_state=42),\n",
        "}\n",
        "\n",
        "model_performance = {}\n",
        "for method, sample_data in sampling_methods.items():\n",
        "    X_sample = sample_data.drop(columns=['Class', 'Cluster'], errors='ignore')\n",
        "    y_sample = sample_data['Class']\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_sample, y_sample, test_size=0.2, random_state=42)\n",
        "\n",
        "    for model_name, model in ml_models.items():\n",
        "        model.fit(X_train, y_train)\n",
        "        acc_score = model.score(X_test, y_test)\n",
        "        if method not in model_performance:\n",
        "            model_performance[method] = {}\n",
        "        model_performance[method][model_name] = acc_score\n",
        "\n",
        "for method, scores in model_performance.items():\n",
        "    for model_name, score in scores.items():\n",
        "        print(f\"Sampling Method: {method} | Model: {model_name} | Accuracy: {score:.2f}\")\n",
        "\n",
        "\n",
        "best_sampling, best_model, top_accuracy = \"\", \"\", 0\n",
        "for method, scores in model_performance.items():\n",
        "    for model_name, score in scores.items():\n",
        "        if score > top_accuracy:\n",
        "            top_accuracy, best_sampling, best_model = score, method, model_name\n",
        "\n",
        "print(\"\\nBest Sampling Technique and Model:\")\n",
        "print(f\"Sampling Method: {best_sampling}\")\n",
        "print(f\"Model: {best_model}\")\n",
        "print(f\"Accuracy: {top_accuracy:.2f}\")\n"
      ]
    }
  ]
}